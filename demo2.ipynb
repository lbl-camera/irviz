{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "annual-temperature",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Infrared Data Analysis\n",
    "\n",
    "The workflow we have here does the following:\n",
    "\n",
    " - First, we read the data and perform some basic 'John Snow' decomposition, like PCA, KernelPCA or ICA.\n",
    " \n",
    " -The results of this decomposition is used to construct an initial set of component spectra that are used to kickstart and MCR-ALS decomposition.\n",
    " - The results of this decomposition is displayed in the IRViz application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32c5c91-6d28-4cef-84df-e546e8d43d03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lbl\\.virtualenvs\\ryujin\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymcr  # install analysis package not included in IRViz dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beginning-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from dask import array as da\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "from irviz.app import open_map_file, open_ir_file\n",
    "import phonetic_alphabet as pa\n",
    "\n",
    "from pymcr.mcr import McrAR\n",
    "from pymcr.regressors import OLS, NNLS\n",
    "from pymcr.constraints import ConstraintNonneg, ConstraintNorm\n",
    "import logging, sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-consciousness",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exempt-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data\n",
    "data_file =  \"E:/BP-area3a.h5\"\n",
    "data, bounds = open_map_file(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-retail",
   "metadata": {},
   "source": [
    "### Do the initial decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "small-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "method = \"KernelPCA\"\n",
    "\n",
    "models = {\"KernelPCA\": sklearn.decomposition.KernelPCA(kernel=\"rbf\", \n",
    "                                        fit_inverse_transform=True, \n",
    "                                        n_components=n_components),\n",
    "        \"PCA\": sklearn.decomposition.PCA(n_components=n_components),\n",
    "        \"ICA\": sklearn.decomposition.FastICA(n_components=n_components) }\n",
    "\n",
    "\n",
    "model = models[method]\n",
    "\n",
    "decomposition = model.fit_transform(\n",
    "    data.transpose(1,2,0).reshape(-1, data.shape[0])).T.reshape(-1, *data.shape[1:])\n",
    "cluster_labels = np.argmax(decomposition, axis=0)\n",
    "\n",
    "cluster_label_names = []\n",
    "label_letters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "for label_letter in label_letters[:n_components]:\n",
    "    cluster_label_names.append( pa.read(label_letter) )\n",
    "\n",
    "decomposition_components = None\n",
    "try:\n",
    "    decomposition_components = model.components_\n",
    "except:\n",
    "    pass\n",
    "\n",
    "mean_spectra = []\n",
    "for ii in range(n_components):\n",
    "    sel = cluster_labels.flatten() == ii\n",
    "    sel = np.where(sel)[0]    \n",
    "    spectra = data.reshape( (data.shape[0],data.shape[1]*data.shape[2]) )[:,sel]\n",
    "    spectra = np.mean( spectra, axis = 1)\n",
    "    mean_spectra.append( spectra ) \n",
    "\n",
    "mean_spectra = np.vstack(mean_spectra)\n",
    "nan_list = np.isnan(mean_spectra.compute())[:,0]\n",
    "n_nans = len(np.where(nan_list)[0])\n",
    "if n_nans >0 :\n",
    "    print(\"Please reduce the number of components to \",n_components - n_nans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-construction",
   "metadata": {},
   "source": [
    "### Here we use the pyMCR package to do MCR analyses\n",
    "\n",
    "We kickstart this by the decomposition done above. This calculation can take a little bit of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "selective-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "mystdout = StringIO()\n",
    "logger = logging.getLogger('pymcr')\n",
    "logger.setLevel(logging.INFO)\n",
    "stdout_handler = logging.StreamHandler(stream=mystdout)\n",
    "\n",
    "# Set the message format. Simple and removing log level or date info\n",
    "stdout_format = logging.Formatter('%(message)s')  # Just a basic message akin to print statements\n",
    "stdout_handler.setFormatter(stdout_format)\n",
    "logger.addHandler(stdout_handler)\n",
    "\n",
    "mcrar = McrAR(max_iter=50, st_regr='NNLS', c_regr=NNLS(), \n",
    "              c_constraints=[ConstraintNonneg()]) \n",
    "\n",
    "# because we use dask arrays, and pymcr wants numpy, some jiggery pokery is happening.\n",
    "mcrar.fit(data.transpose(1,2,0).reshape(-1, data.shape[0]).compute().astype(float), \n",
    "          ST=mean_spectra.compute().astype(float), verbose=False)\n",
    "\n",
    "# now we are done\n",
    "concentrations = mcrar.C_opt_.T.reshape( (n_components, data.shape[1], data.shape[2]) )\n",
    "components = mcrar.ST_opt_\n",
    "# get cluster labels based on the maximum component available\n",
    "cluster_labels = np.argmax(concentrations, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-holder",
   "metadata": {},
   "source": [
    "### Renormalize\n",
    "\n",
    "It makes life easier if we normalize each spectra such that its integrated intensity is equal to mean spectrum. We subsequently rescale the coefficients as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clinical-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first normalize the spectra\n",
    "mean_norm = np.mean( np.sum( data, axis = 0) )\n",
    "norms = np.sum( components, axis =1 )/mean_norm\n",
    "components = (components.T / norms).T\n",
    "\n",
    "# now rescale the concentrations\n",
    "for ii in range(n_components):\n",
    "    concentrations[ii,:]=concentrations[ii,:]/norms[ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-bones",
   "metadata": {},
   "source": [
    "## Create a Viewer\n",
    "Vizualize the results in the IRViz app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inclusive-alcohol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1500\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2ba54cc26a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from irviz.viewer import Viewer\n",
    "viewer = Viewer(data=data,\n",
    "                         decomposition=concentrations,\n",
    "                         bounds=bounds,\n",
    "                         x_axis_title='X (μm)',\n",
    "                         y_axis_title='Y (μm)',\n",
    "                         spectra_axis_title='Wavenumber (cm⁻¹)',\n",
    "                         intensity_axis_title='Intensity',\n",
    "                         invert_spectra_axis=True,\n",
    "                         cluster_labels=cluster_labels,\n",
    "                         cluster_label_names=cluster_label_names,\n",
    "                         component_spectra=components).run_embedded(run_kwargs=dict(height=1500, mode=\"inline\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b8bba-5bad-46fe-b34a-c2b243c9b8be",
   "metadata": {},
   "source": [
    "## Isolate Background\n",
    "Use the IRViz app to interactively determine parameters for background removal\n",
    "\n",
    "First, lets define a function to describe our background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e485f8-3d56-46e9-b4fb-d7ba75382191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import gaussian_process\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF, ConstantKernel as C\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "def GPR_based_background_single_spectrum(wavenumbers,\n",
    "                                         spectrum,\n",
    "                                         control_points,\n",
    "                                         control_regions,\n",
    "                                         mask, # ????????\n",
    "                                         rbf_start=1000,\n",
    "                                         rbf_low=500,\n",
    "                                         rbf_high=1e8,\n",
    "                                         C_start=1.0,\n",
    "                                         C_low=1e-6,\n",
    "                                         C_high=1e4\n",
    "                                         ):\n",
    "    \"\"\"\n",
    "    Build a background model using GPR\n",
    "\n",
    "    :param wavenumbers: Input wavenumbers\n",
    "    :param spectrum: input spectrum\n",
    "    :param control_points: input control points, poicked manually\n",
    "    :param rbf_kernel_params: kernel parameters, defaults ok\n",
    "    :param constant_kernel_params: kernel parameters, defaults ok\n",
    "    :return: a fitted background.\n",
    "    \"\"\"\n",
    "    # gather the x values\n",
    "    these_idxs = []\n",
    "    for cp in control_points:\n",
    "        these_idxs.append( find_nearest(wavenumbers, cp) )\n",
    "    these_idxs = np.array(these_idxs)\n",
    "    these_x = wavenumbers[these_idxs]\n",
    "    these_y = spectrum[these_idxs]\n",
    "    kernel = C(C_start,\n",
    "               (C_low,\n",
    "                C_high)) * \\\n",
    "             RBF(rbf_start, (rbf_low, rbf_high))\n",
    "\n",
    "    gpr = gaussian_process.GaussianProcessRegressor(kernel=kernel).fit(these_x.reshape(-1,1),\n",
    "                                                                       these_y.reshape(-1,1))\n",
    "    tmp_bg = gpr.predict(wavenumbers.reshape(-1,1))\n",
    "    return tmp_bg.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hindu-comfort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2e614ffc370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from irviz import BackgroundIsolator\n",
    "background_isolator = BackgroundIsolator(data=data, bounds=bounds, background_function=GPR_based_background_single_spectrum).run_embedded(run_kwargs=dict(height=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf45090f-906a-4ca7-b79a-ad1c612b0e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_isolator.parameter_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
