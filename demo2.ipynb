{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "annual-temperature",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Infrared Data Analysis\n",
    "\n",
    "The workflow we have here does the following:\n",
    "\n",
    " - First, we read the data and perform some basic 'John Snow' decomposition, like PCA, KernelPCA or ICA.\n",
    " \n",
    " -The results of this decomposition is used to construct an initial set of component spectra that are used to kickstart and MCR-ALS decomposition.\n",
    " - The results of this decomposition is displayed in the IRViz application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beginning-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from dask import array as da\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "from irviz.app import open_map_file, open_ir_file\n",
    "import phonetic_alphabet as pa\n",
    "\n",
    "from pymcr.mcr import McrAR\n",
    "from pymcr.regressors import OLS, NNLS\n",
    "from pymcr.constraints import ConstraintNonneg, ConstraintNorm\n",
    "import logging, sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-consciousness",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exempt-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data\n",
    "data_file =  \"../demo_data/BP-area3a.h5\"\n",
    "data, bounds = open_map_file(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-retail",
   "metadata": {},
   "source": [
    "### Do the initial decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "small-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "method = \"KernelPCA\"\n",
    "\n",
    "models = {\"KernelPCA\": sklearn.decomposition.KernelPCA(kernel=\"rbf\", \n",
    "                                        fit_inverse_transform=True, \n",
    "                                        n_components=n_components),\n",
    "        \"PCA\": sklearn.decomposition.PCA(n_components=n_components),\n",
    "        \"ICA\": sklearn.decomposition.FastICA(n_components=n_components) }\n",
    "\n",
    "\n",
    "model = models[method]\n",
    "\n",
    "decomposition = model.fit_transform(\n",
    "    data.transpose(1,2,0).reshape(-1, data.shape[0])).T.reshape(-1, *data.shape[1:])\n",
    "cluster_labels = np.argmax(decomposition, axis=0)\n",
    "\n",
    "cluster_label_names = []\n",
    "label_letters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "for label_letter in label_letters[:n_components]:\n",
    "    cluster_label_names.append( pa.read(label_letter) )\n",
    "\n",
    "decomposition_components = None\n",
    "try:\n",
    "    decomposition_components = model.components_\n",
    "except:\n",
    "    pass\n",
    "\n",
    "mean_spectra = []\n",
    "for ii in range(n_components):\n",
    "    sel = cluster_labels.flatten() == ii\n",
    "    sel = np.where(sel)[0]    \n",
    "    spectra = data.reshape( (data.shape[0],data.shape[1]*data.shape[2]) )[:,sel]\n",
    "    spectra = np.mean( spectra, axis = 1)\n",
    "    mean_spectra.append( spectra ) \n",
    "\n",
    "mean_spectra = np.vstack(mean_spectra)\n",
    "nan_list = np.isnan(mean_spectra.compute())[:,0]\n",
    "n_nans = len(np.where(nan_list)[0])\n",
    "if n_nans >0 :\n",
    "    print(\"Please reduce the number of components to \",n_components - n_nans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-construction",
   "metadata": {},
   "source": [
    "### Here we use the pyMCR package to do MCR analyses\n",
    "\n",
    "We kickstart this by the decomposition done above. This calculation can take a little bit of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "selective-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "mystdout = StringIO()\n",
    "logger = logging.getLogger('pymcr')\n",
    "logger.setLevel(logging.INFO)\n",
    "stdout_handler = logging.StreamHandler(stream=mystdout)\n",
    "\n",
    "# Set the message format. Simple and removing log level or date info\n",
    "stdout_format = logging.Formatter('%(message)s')  # Just a basic message akin to print statements\n",
    "stdout_handler.setFormatter(stdout_format)\n",
    "logger.addHandler(stdout_handler)\n",
    "\n",
    "mcrar = McrAR(max_iter=50, st_regr='NNLS', c_regr=NNLS(), \n",
    "              c_constraints=[ConstraintNonneg()]) \n",
    "\n",
    "# because we use dask arrays, and pymcr wants numpy, some jiggery pokery is happening.\n",
    "mcrar.fit(data.transpose(1,2,0).reshape(-1, data.shape[0]).compute().astype(float), \n",
    "          ST=mean_spectra.compute().astype(float), verbose=False)\n",
    "\n",
    "# now we are done\n",
    "concentrations = mcrar.C_opt_.T.reshape( (n_components, data.shape[1], data.shape[2]) )\n",
    "components = mcrar.ST_opt_\n",
    "# get cluster labels based on the maximum component available\n",
    "cluster_labels = np.argmax(concentrations, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-holder",
   "metadata": {},
   "source": [
    "### Renormalize\n",
    "\n",
    "It makes life easier if we normalize each spectra such that its integrated intensity is equal to mean spectrum. We subsequently rescale the coefficients as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clinical-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first normalize the spectra\n",
    "mean_norm = np.mean( np.sum( data, axis = 0) )\n",
    "norms = np.sum( components, axis =1 )/mean_norm\n",
    "components = (components.T / norms).T\n",
    "\n",
    "# now rescale the concentrations\n",
    "for ii in range(n_components):\n",
    "    concentrations[ii,:]=concentrations[ii,:]/norms[ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-bones",
   "metadata": {},
   "source": [
    "## Create a Viewer\n",
    "Vizualize the results in the IRViz app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "inclusive-alcohol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "from irviz.viewer import notebook_viewer, Viewer\n",
    "viewer = notebook_viewer(data,\n",
    "                         decomposition=concentrations,\n",
    "                         bounds=bounds,\n",
    "                         x_axis_title='X (μm)',\n",
    "                         y_axis_title='Y (μm)',\n",
    "                         spectra_axis_title='Wavenumber (cm⁻¹)',\n",
    "                         intensity_axis_title='Intensity',\n",
    "                         invert_spectra_axis=True,\n",
    "                         cluster_labels=cluster_labels,\n",
    "                         cluster_label_names=cluster_label_names,\n",
    "                         component_spectra=components,\n",
    "                         height=1500, mode=\"external\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-turkish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-comfort",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}